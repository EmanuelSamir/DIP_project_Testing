{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Lambda, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import glob\n",
    "from scipy.misc import imread,imresize\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from skimage import color\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0 out of 1\n",
      "cannot identify image file './imagen.jpg'\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset:\n",
    "    def __init__(self,image_weight = 224, image_height = 224):\n",
    "        self.image_weight = image_weight\n",
    "        self.image_height = image_height\n",
    "        self.dataset_path = './'#'../../Descargas/AVA/ava_downloader/image/'\n",
    "        self.start_idx = 0\n",
    "        self.end_idx = 1\n",
    "        \n",
    "        self.input_image = []\n",
    "        self.input_hist = []\n",
    "        self.output = []\n",
    "        \n",
    "        \n",
    "        self.dataset_load()\n",
    "        \n",
    "    def dataset_load(self):\n",
    "        raw_image_list = glob.glob(self.dataset_path + '*.jpg')\n",
    "        raw_image_list = sorted(raw_image_list)[self.start_idx:self.end_idx]\n",
    "        print raw_image_list\n",
    "        \n",
    "        for i, img_path in enumerate(raw_image_list):\n",
    "            if i%100 == 0:\n",
    "                print (\"processed %d out of %d\" %( i, len(raw_image_list) ))\n",
    "            try:\n",
    "                \"\"\"\n",
    "                image = imresize(imread(img_path), (self.image_weight,self.image_height))#/255.0-0.5\n",
    "                #image = image.img_to_array(image)\n",
    "                #image = np.expand_dims(image)\n",
    "                #image = image.img_to_array(image, axis = 0)\n",
    "                image = preprocess_input(image)\n",
    "                self.input_image.append(image)\n",
    "                \"\"\"\n",
    "                print 'done image', i\n",
    "                img = image.load_img(img_path, target_size=(224, 224))\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "                self.input_image.append(x)\n",
    "                \n",
    "                \n",
    "                \n",
    "                color_hist = lab_hist(x)\n",
    "                self.input_hist.append(np.stack(np.array(color_hist)))\n",
    "                \n",
    "                parameters = np.ones(6)\n",
    "                image_flat = x.flatten()\n",
    "                output = np.concatenate([parameters , image_flat])\n",
    "                self.output.append(output)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print str(e)\n",
    "\n",
    "    \n",
    "def lab_hist(image_np):\n",
    "    image_np_rgb = image_np/255.0 # 0~1 rgb\n",
    "    image_np_lab = color.rgb2lab(image_np_rgb)\n",
    "\n",
    "    num_bin_L = 10\n",
    "    num_bin_a = 10\n",
    "    num_bin_b = 10\n",
    "\n",
    "    L_max = 100\n",
    "    L_min = 0\n",
    "    a_max = 60\n",
    "    a_min = -60\n",
    "    b_max = 60\n",
    "    b_min = -60\n",
    "    image_np_lab = image_np_lab.reshape([224*224,3])\n",
    "    H, edges = np.histogramdd(image_np_lab, bins=(num_bin_L, num_bin_a, num_bin_b), \\\n",
    "            range=((L_min, L_max), (a_min, a_max), (b_min, b_max)))\n",
    "    return H.reshape(1000)/1000.0\n",
    "        \n",
    "mydata = ImageDataset();\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, image_weight = 224, image_height = 224):\n",
    "        self.image_size = (image_weight, image_height,3)\n",
    "        self.hist_size = 1000\n",
    "        self.batch_size = 4\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.2)\n",
    "        \n",
    "        self.input_image = Input(shape = self.image_size, name='input_image')\n",
    "        self.feature_NN = self.build_VGG()(self.input_image)\n",
    "               \n",
    "        \n",
    "        self.input_hist = Input(shape = (self.hist_size,), name='input_hist')\n",
    "        x = keras.layers.concatenate([self.feature_NN, self.input_hist])\n",
    "        self.parameters_NN = self.build_NN()(x)\n",
    "        \n",
    "        z = Flatten()(self.input_image)\n",
    "        \n",
    "        #z = Input(shape=(self.image_size))(self.input_image)\n",
    "        self.output = keras.layers.concatenate([z, self.parameters_NN])\n",
    "\n",
    "        self.combined = Model([self.input_image, self.input_hist], self.output)\n",
    "        #self.combined.compile(loss = _loss_f, optimizer = optimizer)\n",
    "        \n",
    "        \n",
    "    def build_NN(self, input_size = (5096,)):\n",
    "        inputs = Input(shape = input_size)\n",
    "        x = Dense(512, activation = 'relu')(inputs)\n",
    "        x = Dense(64, activation = 'relu')(x)\n",
    "        parameters = Dense(6, activation = 'linear')(x)\n",
    "        model = Model(inputs=inputs, outputs=parameters)\n",
    "        # model.summary\n",
    "        return model\n",
    "        \n",
    "    def build_VGG(self, istrainable = False):\n",
    "        model = VGG16(weights = 'imagenet')\n",
    "        layer_name = 'fc2'\n",
    "        model2 = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "        model2.trainable = istrainable\n",
    "        return model2\n",
    "        \n",
    "class DeepFeatureNetwork:\n",
    "    def __init__(self, input_size, model_func, model_path):\n",
    "        self.input_tensor = tf.placeholder(tf.float32, shape=input_size)\n",
    "        self.feature, self.weights = model_func(self.input_tensor, model_path)\n",
    "        \n",
    "    def init_model(self):\n",
    "        tf.initialize_variables(self.weights).run()\n",
    "\n",
    "    def get_feature(self, in_data):\n",
    "        return sess.run(self.feature, feed_dict={self.input_tensor: in_data+0.5})\n",
    "    \n",
    "myNN = NeuralNetwork()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_47 (Model)                (None, 4096)         134260544   input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_hist (InputLayer)         (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 5096)         0           model_47[1][0]                   \n",
      "                                                                 input_hist[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 150528)       0           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "model_48 (Model)                (None, 6)            2642886     concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 150534)       0           flatten_8[0][0]                  \n",
      "                                                                 model_48[1][0]                   \n",
      "==================================================================================================\n",
      "Total params: 136,903,430\n",
      "Trainable params: 2,642,886\n",
      "Non-trainable params: 134,260,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myNN.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myNN = NeuralNetwork(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_weight = 224\n",
    "image_height = 224\n",
    "\n",
    "image_size = (image_weight, image_height,3)\n",
    "hist_size = 1000\n",
    "batch_size = 4\n",
    "\n",
    "optimizer = Adam(0.0002, 0.2)\n",
    "\n",
    "input_image = Input(shape = image_size, name = 'input_image')\n",
    "\n",
    "\n",
    "model_build_VGG = VGG16(weights = 'imagenet')\n",
    "layer_name = 'fc2'\n",
    "model_build_VGG_ = Model(inputs=model_build_VGG.input, outputs=model_build_VGG.get_layer(layer_name).output)\n",
    "model_build_VGG_.trainable = False\n",
    "\n",
    "feature_NN = model_build_VGG_(input_image)\n",
    "\n",
    "\n",
    "\n",
    "#input_hist = Input(shape = (hist_size,), name='input_hist')\n",
    "#x_ = keras.layers.concatenate([feature_NN, input_hist])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#input_hist = Input(shape = hist_size, name='input_hist')\n",
    "#x = keras.layers.concatenate([feature_NN, input_hist])\n",
    "#parameter_NN = build_NN()(x)\n",
    "\n",
    "#z = Input(shape = (image_size))(input_image)\n",
    "#output = keras.layer.concatenate([z, parameters_NN])\n",
    "\n",
    "#combined = Model([input_image, input_hist], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "myf = Flatten()(input_image)\n",
    "\n",
    "x_ = keras.layers.concatenate([feature_NN, input_hist])\n",
    "inputs = Input(shape = (5096,))\n",
    "x = Dense(250, activation = 'relu')(inputs)\n",
    "x = Dense(100, activation = 'relu')(x)\n",
    "parameters = Dense(6, activation = 'linear')(x)\n",
    "model2 = Model(inputs=inputs, outputs=parameters)\n",
    "\n",
    "parameter_NN = model2(x_)\n",
    "#z = Input(shape = image_size)\n",
    "#z = z(input_image)\n",
    "output = keras.layers.concatenate([myf, parameter_NN])\n",
    "\n",
    "combined = Model([input_image, input_hist], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Model(inputs = [input_hist, input_image], outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c61ab43bde50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameter_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "parameter_NN.summary()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "cannot identify image file u'./imagen.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-7c3b05eb2aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'./imagen.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmyimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(name, flatten, mode)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \"\"\"\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: cannot identify image file u'./imagen.jpg'"
     ]
    }
   ],
   "source": [
    "path=u'./imagen.jpg'\n",
    "myimage = imread(name = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 21] Is a directory: u'/home/emanuelsamir/UTEC/6to_ciclo/Digital_Image_Processing/project/Park_code/DISTORT-AND-RECOVER-CVPR18/DIP_project_Testing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-419e89fd7ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m image=Image.open(u'/home/emanuelsamir/UTEC/6to_ciclo/Digital_Image_Processing/project/Park_code/DISTORT-AND-RECOVER-CVPR18/DIP_project_Testing'\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 21] Is a directory: u'/home/emanuelsamir/UTEC/6to_ciclo/Digital_Image_Processing/project/Park_code/DISTORT-AND-RECOVER-CVPR18/DIP_project_Testing'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image=Image.open(u'home/emanuelsamir/UTEC/6to_ciclo/Digital_Image_Processing/project/Park_code/DISTORT-AND-RECOVER-CVPR18/DIP_project_Testing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building.ipynb  \u001b[0m\u001b[01;35mFig0458(a)(blurry_moon).tif\u001b[0m  \u001b[01;35mimagen.jpg\u001b[0m  \u001b[01;35mimagen.tiff\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape = image_size, name = 'input_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-96571f16397f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "myf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
