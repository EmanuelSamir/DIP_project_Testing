{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "import glob\n",
    "from scipy.misc import imread,imresize\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import skimage.color as color\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset:\n",
    "    def __init__(self,image_weight = 224, image_height = 224):\n",
    "        self.image_weight = image_weight\n",
    "        self.image_height = image_height\n",
    "        self.dataset_path = '../../Descargas/AVA/ava_downloader/image/'\n",
    "        self.start_idx = 1\n",
    "        self.end_idx = 100\n",
    "        \n",
    "        \n",
    "        self.input_load()\n",
    "        self.pred = self.pred_load()\n",
    "        \n",
    "    def data_input(self):\n",
    "        raw_image_list = glob.glob(self.dataset.path + '*.jpg')\n",
    "        raw_img_list = sorted(raw_img_list)[self.start_idx:self.end_idx]\n",
    "        self.input.image = []\n",
    "        self.input.hist = []\n",
    "        for i, img_path in enumerate(raw_img_list):\n",
    "            if i%100 == 0:\n",
    "                print (\"processed %d out of %d\" %( i, len(raw_img_list) ))\n",
    "            try:\n",
    "                image = imresize(imread(img_path), (self.image_weight,self.image_height))\n",
    "                image = image.img_to_array(image)\n",
    "                image = np.expand_dims(image)\n",
    "                image = image.img_to_array(image, axis = 0)\n",
    "                image = preprocess_input(image)\n",
    "                self.input.image.append(image)\n",
    "                \n",
    "                color_hist = lab_hist(image)\n",
    "                self.input.hist.append(np.stack(np.array(color_hist)))\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print str(e)\n",
    "        \n",
    "    def data_pred(self):\n",
    "        pass\n",
    "    #def prepare_image\n",
    "    \n",
    "def lab_hist(image_np):\n",
    "    image_np_rgb = image_np + 0.5 # 0~1 rgb\n",
    "    image_np_lab = color.rgb2lab(image_np_rgb)\n",
    "\n",
    "    num_bin_L = 10\n",
    "    num_bin_a = 10\n",
    "    num_bin_b = 10\n",
    "\n",
    "    L_max = 100\n",
    "    L_min = 0\n",
    "    a_max = 60\n",
    "    a_min = -60\n",
    "    b_max = 60\n",
    "    b_min = -60\n",
    "    image_np_lab = image_np_lab.reshape([224*224,3])\n",
    "    H, edges = np.histogramdd(image_np_lab, bins=(num_bin_L, num_bin_a, num_bin_b), \\\n",
    "            range=((L_min, L_max), (a_min, a_max), (b_min, b_max)))\n",
    "    return H.reshape(1000)/1000.0\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9870f561d1a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmyNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-9870f561d1a1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_weight, image_height)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_hist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_hist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/keras/engine/input_layer.pyc\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    169\u001b[0m                                    'dimension.')\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, image_weight = 224, image_height = 224):\n",
    "        self.image_size = (image_weight, image_height,3)\n",
    "        self.hist_size = 100\n",
    "        self.batch_size = 4\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.2)\n",
    "        \n",
    "        self.input_image = Input(shape = self.image_size)\n",
    "        self.feature_NN = self.build_VGG()(self.input_image)\n",
    "               \n",
    "        \n",
    "        self.input_hist = Input(shape = self.hist_size, name='input_hist')\n",
    "        x = keras.layers.concatenate([self.feature_NN, self.input_hist])\n",
    "        self.parameter_NN = self.build_NN()(x)\n",
    "        \n",
    "        z = Input(shape=(self.image_size))(self.input_image)\n",
    "        self.output = keras.layer.concatenate([z, self.parameters_NN])\n",
    "\n",
    "        self.combined = Model([self.input_image, self.input_hist], self.output)\n",
    "        #self.combined.compile(loss = _loss_f, optimizer = optimizer)\n",
    "        \n",
    "        \n",
    "    def build_NN(self, input_size):\n",
    "        inputs = Input(shape = input_size)\n",
    "        x = Dense(250, activation = 'relu')(inputs)\n",
    "        x = Dense(100, activation = 'relu')(x)\n",
    "        parameters = Dense(6, activation = 'linear')(x)\n",
    "        model = Model(inputs=inputs, outputs=parameters)\n",
    "        # model.summary\n",
    "        return model\n",
    "        \n",
    "    def build_VGG(self, istrainable = False):\n",
    "        model = VGG16(weights = 'imagenet')\n",
    "        layer_name = 'fc2'\n",
    "        model2 = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "        model2.trainable = istrainable\n",
    "        return model2\n",
    "        \n",
    "class DeepFeatureNetwork:\n",
    "    def __init__(self, input_size, model_func, model_path):\n",
    "        self.input_tensor = tf.placeholder(tf.float32, shape=input_size)\n",
    "        self.feature, self.weights = model_func(self.input_tensor, model_path)\n",
    "        \n",
    "    def init_model(self):\n",
    "        tf.initialize_variables(self.weights).run()\n",
    "\n",
    "    def get_feature(self, in_data):\n",
    "        return sess.run(self.feature, feed_dict={self.input_tensor: in_data+0.5})\n",
    "    \n",
    "myNN = NeuralNetwork(224,224)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 250, 250)          0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 250, 250)          62750     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 250, 100)          25100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 250, 6)            606       \n",
      "=================================================================\n",
      "Total params: 88,456\n",
      "Trainable params: 0\n",
      "Non-trainable params: 88,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'build_VGG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-465735d21b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-c61f4d08b40f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_weight, image_height)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_VGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'build_VGG' is not defined"
     ]
    }
   ],
   "source": [
    "myNN = NeuralNetwork(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
