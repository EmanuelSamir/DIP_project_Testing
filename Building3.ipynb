{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Lambda, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import glob\n",
    "from scipy.misc import imread,imresize\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from skimage import color\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./A/test/images/000027.jpg__0.052476.jpg', './A/test/images/000047.jpg__0.853644.jpg', './A/test/images/000048.jpg__0.057931.jpg', './A/test/images/000065.jpg__0.000169.jpg', './A/test/images/000096.jpg__1.149314.jpg', './A/test/images/000103.jpg__0.166729.jpg', './A/test/images/000119.jpg__0.180421.jpg', './A/test/images/000129.jpg__0.000262.jpg', './A/test/images/000136.jpg__0.029303.jpg', './A/test/images/000147.jpg__0.069185.jpg']\n",
      "processed 0 out of 10\n",
      "done distorted image 0\n",
      "done distorted image 1\n",
      "done distorted image 2\n",
      "done distorted image 3\n",
      "done distorted image 4\n",
      "done distorted image 5\n",
      "done distorted image 6\n",
      "done distorted image 7\n",
      "done distorted image 8\n",
      "done distorted image 9\n",
      "processed 0 out of 10\n",
      "done original image 0\n",
      "done original image 1\n",
      "done original image 2\n",
      "done original image 3\n",
      "done original image 4\n",
      "done original image 5\n",
      "done original image 6\n",
      "done original image 7\n",
      "done original image 8\n",
      "done original image 9\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset:\n",
    "    def __init__(self,image_weight = 224, image_height = 224):\n",
    "        self.image_weight = image_weight\n",
    "        self.image_height = image_height\n",
    "        self.distort_path = './A/test/images/'#'../../Descargas/ava_downloader/image/'\n",
    "        self.original_path = './A/test/target/'\n",
    "        self.start_idx = 0\n",
    "        self.end_idx = 10\n",
    "        \n",
    "        self.input_image = []\n",
    "        self.input_hist = []\n",
    "        self.output = []\n",
    "        \n",
    "        \n",
    "        self.input_load()\n",
    "        self.pred_load()\n",
    "        \n",
    "    def input_load(self):\n",
    "        raw_image_list = glob.glob(self.distort_path + '*.jpg')\n",
    "        raw_image_list = sorted(raw_image_list)[self.start_idx:self.end_idx]\n",
    "        print raw_image_list\n",
    "        \n",
    "        for i, img_path in enumerate(raw_image_list):\n",
    "            if i%100 == 0:\n",
    "                print (\"processed %d out of %d\" %( i, len(raw_image_list) ))\n",
    "            try:\n",
    "                \"\"\"\n",
    "                image = imresize(imread(img_path), (self.image_weight,self.image_height))#/255.0-0.5\n",
    "                #image = image.img_to_array(image)\n",
    "                #image = np.expand_dims(image)\n",
    "                #image = image.img_to_array(image, axis = 0)\n",
    "                image = preprocess_input(image)\n",
    "                self.input_image.append(image)\n",
    "                \"\"\"\n",
    "                print 'done distorted image', i\n",
    "                img = image.load_img(img_path, target_size=(224, 224))\n",
    "                x = image.img_to_array(img)\n",
    "                #x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "                self.input_image.append(x)\n",
    "                \n",
    "                \n",
    "                color_hist = lab_hist(x)\n",
    "                self.input_hist.append(np.stack(np.array(color_hist)))\n",
    "                \n",
    "                #parameters = np.ones(6)\n",
    "                #image_flat = x.flatten()\n",
    "                #output = np.concatenate([parameters , image_flat])\n",
    "                #self.output.append(output)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print str(e)\n",
    "                \n",
    "                \n",
    "    def pred_load(self):\n",
    "        raw_image_list = glob.glob(self.original_path + '*.jpg')\n",
    "        raw_image_list = sorted(raw_image_list)[self.start_idx:self.end_idx]\n",
    "        \n",
    "        for i, img_path in enumerate(raw_image_list):\n",
    "            if i%100 == 0:\n",
    "                print (\"processed %d out of %d\" %( i, len(raw_image_list) ))\n",
    "            try:\n",
    "                \"\"\"\n",
    "                image = imresize(imread(img_path), (self.image_weight,self.image_height))#/255.0-0.5\n",
    "                #image = image.img_to_array(image)\n",
    "                #image = np.expand_dims(image)\n",
    "                #image = image.img_to_array(image, axis = 0)\n",
    "                image = preprocess_input(image)\n",
    "                self.input_image.append(image)\n",
    "                \"\"\"\n",
    "                print 'done original image', i\n",
    "                img = image.load_img(img_path, target_size=(224, 224))\n",
    "                x = image.img_to_array(img)\n",
    "                 \n",
    "                \n",
    "                #x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "                #self.input_image.append(x)\n",
    "               \n",
    "                \n",
    "                #color_hist = lab_hist(x)\n",
    "                #self.input_hist.append(np.stack(np.array(color_hist)))\n",
    "                \n",
    "                parameters = np.ones(6)\n",
    "                image_flat = x.flatten()\n",
    "                output = np.concatenate([parameters , image_flat])\n",
    "                self.output.append(output)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print str(e)\n",
    "                \n",
    "    \n",
    "def lab_hist(image_np):\n",
    "    image_np_rgb = image_np/255.0 # 0~1 rgb\n",
    "    image_np_lab = color.rgb2lab(image_np_rgb)\n",
    "\n",
    "    num_bin_L = 10\n",
    "    num_bin_a = 10\n",
    "    num_bin_b = 10\n",
    "\n",
    "    L_max = 100\n",
    "    L_min = 0\n",
    "    a_max = 60\n",
    "    a_min = -60\n",
    "    b_max = 60\n",
    "    b_min = -60\n",
    "    image_np_lab = image_np_lab.reshape([224*224,3])\n",
    "    H, edges = np.histogramdd(image_np_lab, bins=(num_bin_L, num_bin_a, num_bin_b), \\\n",
    "            range=((L_min, L_max), (a_min, a_max), (b_min, b_max)))\n",
    "    return H.reshape(1000)/1000.0\n",
    "        \n",
    "mydata = ImageDataset()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 2 for 'loss_2/concatenate_8_loss/Slice' (op: 'Slice') with input shapes: [?,?], [1], [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-bb5a5a946dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m \u001b[0mmyNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-273-bb5a5a946dbe>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_weight, image_height)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_hist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loss_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 333\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    334\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-273-bb5a5a946dbe>\u001b[0m in \u001b[0;36m_loss_f\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#parameter_6 = K.slice(y_pred,[5],[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mimage_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mslice\u001b[0;34m(x, start, size)\u001b[0m\n\u001b[1;32m   2360\u001b[0m                   start[-1]: start[-1] + size[-1]]`\n\u001b[1;32m   2361\u001b[0m     \"\"\"\n\u001b[0;32m-> 2362\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m   \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   7091\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7092\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 7093\u001b[0;31m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[0m\u001b[1;32m   7094\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7095\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alumno04/dev_samir/venv_tf_GPU_p/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 2 for 'loss_2/concatenate_8_loss/Slice' (op: 'Slice') with input shapes: [?,?], [1], [1]."
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, image_weight = 224, image_height = 224):\n",
    "        self.image_size = (image_weight, image_height,3)\n",
    "        self.hist_size = 1000\n",
    "        self.batch_size = 4\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.2)\n",
    "        \n",
    "        self.input_image = Input(shape = self.image_size, name='input_image')\n",
    "        self.feature_NN = self.build_VGG()(self.input_image)\n",
    "               \n",
    "        \n",
    "        self.input_hist = Input(shape = (self.hist_size,), name='input_hist')\n",
    "        x = keras.layers.concatenate([self.feature_NN, self.input_hist])\n",
    "        self.parameters_NN = self.build_NN()(x)\n",
    "        \n",
    "        z = Flatten()(self.input_image)\n",
    "        \n",
    "        #z = Input(shape=(self.image_size))(self.input_image)\n",
    "        self.output = keras.layers.concatenate([z, self.parameters_NN])\n",
    "\n",
    "        self.combined = Model([self.input_image, self.input_hist], self.output)\n",
    "        self.combined.compile(loss = _loss_f, optimizer = optimizer)\n",
    "        \n",
    "        \n",
    "    def build_NN(self, input_size = (5096,)):\n",
    "        inputs = Input(shape = input_size)\n",
    "        x = Dense(512, activation = 'relu')(inputs)\n",
    "        x = Dense(64, activation = 'relu')(x)\n",
    "        parameters = Dense(6, activation = 'linear')(x)\n",
    "        model = Model(inputs=inputs, outputs=parameters)\n",
    "        # model.summary\n",
    "        return model\n",
    "        \n",
    "    def build_VGG(self, istrainable = False):\n",
    "        model = VGG16(weights = 'imagenet')\n",
    "        layer_name = 'fc2'\n",
    "        model2 = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "        model2.trainable = istrainable\n",
    "        return model2\n",
    "        \n",
    "class DeepFeatureNetwork:\n",
    "    def __init__(self, input_size, model_func, model_path):\n",
    "        self.input_tensor = tf.placeholder(tf.float32, shape=input_size)\n",
    "        self.feature, self.weights = model_func(self.input_tensor, model_path)\n",
    "        \n",
    "    def init_model(self):\n",
    "        tf.initialize_variables(self.weights).run()\n",
    "\n",
    "    def get_feature(self, in_data):\n",
    "        return sess.run(self.feature, feed_dict={self.input_tensor: in_data+0.5})\n",
    "    \n",
    "def _loss_f(y_true, y_pred):\n",
    "    \n",
    "    y_pred = y_pred[:,:]\n",
    "    #parameter_1 = K.slice(y_pred,[0],[1])\n",
    "    #parameter_2 = K.slice(y_pred,[1],[1])\n",
    "    #parameter_3 = K.slice(y_pred,[2],[1])\n",
    "    #parameter_4 = K.slice(y_pred,[3],[1])\n",
    "    #parameter_5 = K.slice(y_pred,[4],[1])\n",
    "    #parameter_6 = K.slice(y_pred,[5],[1])\n",
    "    \n",
    "    x = K.slice(y_pred, [6],[-1])\n",
    "    \n",
    "    image_pred = K.reshape(x,[224,224,3])\n",
    "    \n",
    "    x = K.slice(y_true,[6],[-1])\n",
    "    \n",
    "    image_true = K.reshape(x,[224,224,3])\n",
    "    \n",
    "    # Contrast\n",
    "    contrast_mean = K.mean(image_pred)\n",
    "    contrast_degenerate = K.zeros([224,224,3]) + contrast_mean\n",
    "    \n",
    "    image_pred = parameter_1 * image_pred + (1-parameter_1)*contrast_degenerate\n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "     # Brightness\n",
    "    #brightness_degenerate = np.zeros(image_pred.shape)\n",
    "    \n",
    "    image_pred = parameter_2 * image_pred # + (1 - parameters[1]) * brightness_degenerate\n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "    # Color Saturation\n",
    "    \n",
    "    saturation_degenerate = K.mean(image_pred,2)\n",
    "    \n",
    "    red_layer = K.slice(image_pred,[0,0,0],[-1,-1,1])\n",
    "    blue_layer = K.slice(image_pred,[0,0,1],[-1,-1,1])\n",
    "    green_layer = K.slice(image_pred,[0,0,2],[-1,-1,1])\n",
    "    \n",
    "    red_layer_ = (parameter_3 * red_layer) + K.expand_dims( (1- parameter_3) * saturation_degenerate, axis= 2)\n",
    "    blue_layer_ = (parameter_3 * blue_layer) +  K.expand_dims( (1- parameter_3) * saturation_degenerate, axis= 2)\n",
    "    green_layer_ = (parameter_3 * green_layer) +  K.expand_dims( (1- parameter_3) * saturation_degenerate, axis= 2)\n",
    "    \n",
    "    image_pred = K.concatenate ([red_layer_, blue_layer_, green_layer_], axis =2)\n",
    "    \n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "    # White Balance\n",
    "    red_layer = K.slice(image_pred,[0,0,0],[-1,-1,1])\n",
    "    blue_layer = K.slice(image_pred,[0,0,1],[-1,-1,1])\n",
    "    green_layer = K.slice(image_pred,[0,0,2],[-1,-1,1]) \n",
    "    \n",
    "    red_layer_ = (parameter_4 * red_layer) \n",
    "    blue_layer_ = (parameter_5 * blue_layer)\n",
    "    green_layer_ = (parameter_6 * green_layer)\n",
    "    \n",
    "    image_pred = K.concatenate ([red_layer_, blue_layer_, green_layer_], axis =2)\n",
    "    \n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "    mse = K.mean(K.square(image_pred - image_true))\n",
    "    \n",
    "    return  mse \n",
    "        \n",
    "    \n",
    "\"\"\"    \n",
    "def _loss_f(y_true, y_pred):\n",
    "    \n",
    "        \n",
    "    parameter_1 = K.slice(y_pred,[0],[1])\n",
    "    parameter_2 = K.slice(y_pred,[1],[1])\n",
    "    parameter_3 = K.slice(y_pred,[2],[1])\n",
    "    parameter_4 = K.slice(y_pred,[3],[1])\n",
    "    parameter_5 = K.slice(y_pred,[4],[1])\n",
    "    parameter_6 = K.slice(y_pred,[5],[1])\n",
    "    \n",
    "    x = K.slice(y_pred, [6],[-1])\n",
    "    \n",
    "    image_pred = K.reshape(x,[224,224,3])\n",
    "    \n",
    "    x = K.slice(y_true,[6],[-1])\n",
    "    \n",
    "    image_true = K.reshape(x,[224,224,3])\n",
    "    \n",
    "    # Contrast\n",
    "    contrast_mean = K.mean(image_pred)\n",
    "    contrast_degenerate = K.zeros(224,224,3) + contrast_mean\n",
    "    \n",
    "    image_pred = parameter_1 * image_pred + (1-parameter_1)*contrast_degenerate\n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "     # Brightness\n",
    "    #brightness_degenerate = np.zeros(image_pred.shape)\n",
    "    \n",
    "    image_pred = parameter_2 * image_pred # + (1 - parameters[1]) * brightness_degenerate\n",
    "    image_pred = np.clip(image_pred,0,1)\n",
    "    \n",
    "    \n",
    "    x = np.split(y_pred,[6])\n",
    "\n",
    "x = K.slice(y_pred, [1],[6])\n",
    "y = K.slice(y_pred, [6],[-1])\n",
    "z = K.reshape(y_pred,[3,3,3])\n",
    "    \n",
    "    \n",
    "    parameters = x[0]\n",
    "    image_pred = x[1].reshape(224,224,3)\n",
    "    \n",
    "    y = np.split(y_true,[6])\n",
    "    image_true = y[1].reshape(224,224,3)\n",
    "    \n",
    "    # Contrast\n",
    "    contrast_mean = np.mean(image_pred)\n",
    "    contrast_degenerate = np.zeros(image_pred.shape)\n",
    "    \n",
    "    image_pred = parameters[0] * image_pred + (1-parameters[0])*contrast_degenerate\n",
    "    image_pred = np.clip(image_pred,0,1)\n",
    "    \n",
    "    # Brightness\n",
    "    brightness_degenerate = np.zeros(image_pred.shape)\n",
    "    \n",
    "    image_pred = parameters[1] * image_pred + (1 - parameters[1]) * brightness_degenerate\n",
    "    image_pred = np.clip(image_pred,0,1)\n",
    "    \n",
    "    # Color Saturation\n",
    "    saturation_degenerate = image_pred.mean(axis= 2)\n",
    "    \n",
    "    image_pred[:,:,0] = parameters[2] * image_pred[:,:,0] + (1-parameters[2]) * saturation_degenerate\n",
    "    image_pred[:,:,1] = parameters[2] * image_pred[:,:,1] + (1-parameters[2]) * saturation_degenerate\n",
    "    image_pred[:,:,2] = parameters[2] * image_pred[:,:,2] + (1-parameters[2]) * saturation_degenerate\n",
    "    \n",
    "    # White Balance\n",
    "    image_pred[:,:,0] = parameters[3] * image_pred[:,:,0]\n",
    "    image_pred[:,:,1] = parameters[4] * image_pred[:,:,1]\n",
    "    image_pred[:,:,2] = parameters[5] * image_pred[:,:,2]\n",
    "    \n",
    "    image_pred = np.clip(image_pred,0,1)\n",
    "    \n",
    "    mse = (np.square(image_pred - image_true)).mean(axis=None)\n",
    "    \n",
    "    return mse\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "myNN = NeuralNetwork()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 4096)         134260544   input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_hist (InputLayer)         (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5096)         0           model_1[1][0]                    \n",
      "                                                                 input_hist[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 150528)       0           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 6)            2642886     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 150534)       0           flatten_1[0][0]                  \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 136,903,430\n",
      "Trainable params: 2,642,886\n",
      "Non-trainable params: 134,260,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myNN.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myNN = NeuralNetwork(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_weight = 224\n",
    "image_height = 224\n",
    "\n",
    "image_size = (image_weight, image_height,3)\n",
    "hist_size = 1000\n",
    "batch_size = 4\n",
    "\n",
    "optimizer = Adam(0.0002, 0.2)\n",
    "\n",
    "input_image = Input(shape = image_size, name = 'input_image')\n",
    "\n",
    "\n",
    "model_build_VGG = VGG16(weights = 'imagenet')\n",
    "layer_name = 'fc2'\n",
    "model_build_VGG_ = Model(inputs=model_build_VGG.input, outputs=model_build_VGG.get_layer(layer_name).output)\n",
    "model_build_VGG_.trainable = False\n",
    "\n",
    "feature_NN = model_build_VGG_(input_image)\n",
    "\n",
    "\n",
    "\n",
    "#input_hist = Input(shape = (hist_size,), name='input_hist')\n",
    "#x_ = keras.layers.concatenate([feature_NN, input_hist])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#input_hist = Input(shape = hist_size, name='input_hist')\n",
    "#x = keras.layers.concatenate([feature_NN, input_hist])\n",
    "#parameter_NN = build_NN()(x)\n",
    "\n",
    "#z = Input(shape = (image_size))(input_image)\n",
    "#output = keras.layer.concatenate([z, parameters_NN])\n",
    "\n",
    "#combined = Model([input_image, input_hist], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "myf = Flatten()(input_image)\n",
    "\n",
    "x_ = keras.layers.concatenate([feature_NN, input_hist])\n",
    "inputs = Input(shape = (5096,))\n",
    "x = Dense(250, activation = 'relu')(inputs)\n",
    "x = Dense(100, activation = 'relu')(x)\n",
    "parameters = Dense(6, activation = 'linear')(x)\n",
    "model2 = Model(inputs=inputs, outputs=parameters)\n",
    "\n",
    "parameter_NN = model2(x_)\n",
    "#z = Input(shape = image_size)\n",
    "#z = z(input_image)\n",
    "output = keras.layers.concatenate([myf, parameter_NN])\n",
    "\n",
    "combined = Model([input_image, input_hist], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Model(inputs = [input_hist, input_image], outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c61ab43bde50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameter_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "parameter_NN.summary()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = mydata.input_image[0]\n",
    "np.array(y_true).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ -89.939   ,  -98.779   , -104.68    ],\n",
       "          [ -82.939   ,  -91.779   ,  -97.68    ],\n",
       "          [ -75.939   ,  -84.779   ,  -90.68    ],\n",
       "          ...,\n",
       "          [ -29.939003,  -46.779   ,  -58.68    ],\n",
       "          [ -28.939003,  -47.779   ,  -61.68    ],\n",
       "          [ -29.939003,  -48.779   ,  -62.68    ]],\n",
       " \n",
       "         [[ -89.939   ,  -98.779   , -104.68    ],\n",
       "          [ -85.939   ,  -94.779   , -100.68    ],\n",
       "          [ -80.939   ,  -89.779   ,  -95.68    ],\n",
       "          ...,\n",
       "          [ -28.939003,  -45.779   ,  -57.68    ],\n",
       "          [ -30.939003,  -47.779   ,  -59.68    ],\n",
       "          [ -29.939003,  -48.779   ,  -62.68    ]],\n",
       " \n",
       "         [[ -78.939   ,  -87.779   ,  -93.68    ],\n",
       "          [ -80.939   ,  -89.779   ,  -95.68    ],\n",
       "          [ -82.939   ,  -91.779   ,  -97.68    ],\n",
       "          ...,\n",
       "          [ -30.939003,  -47.779   ,  -59.68    ],\n",
       "          [ -32.939003,  -49.779   ,  -61.68    ],\n",
       "          [ -34.939003,  -51.779   ,  -63.68    ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -17.939003,  -37.779   ,  -47.68    ],\n",
       "          [ -14.939003,  -34.779   ,  -44.68    ],\n",
       "          [ -11.939003,  -31.779   ,  -41.68    ],\n",
       "          ...,\n",
       "          [ -95.939   ,  -77.779   ,  -91.68    ],\n",
       "          [ -97.939   ,  -79.779   ,  -93.68    ],\n",
       "          [-101.939   ,  -83.779   ,  -97.68    ]],\n",
       " \n",
       "         [[ -13.939003,  -35.779   ,  -45.68    ],\n",
       "          [ -11.939003,  -33.779   ,  -43.68    ],\n",
       "          [  -8.939003,  -30.779   ,  -40.68    ],\n",
       "          ...,\n",
       "          [ -91.939   ,  -73.779   ,  -87.68    ],\n",
       "          [ -91.939   ,  -73.779   ,  -87.68    ],\n",
       "          [ -96.939   ,  -78.779   ,  -92.68    ]],\n",
       " \n",
       "         [[ -12.939003,  -34.779   ,  -44.68    ],\n",
       "          [ -11.939003,  -33.779   ,  -43.68    ],\n",
       "          [  -9.939003,  -31.779   ,  -41.68    ],\n",
       "          ...,\n",
       "          [ -91.939   ,  -73.779   ,  -87.68    ],\n",
       "          [ -91.939   ,  -73.779   ,  -87.68    ],\n",
       "          [ -95.939   ,  -77.779   ,  -91.68    ]]]], dtype=float32),\n",
       " array([[[[ -50.939003 ,  -53.779    ,  -42.68     ],\n",
       "          [ -51.939003 ,  -54.779    ,  -43.68     ],\n",
       "          [ -52.939003 ,  -55.779    ,  -44.68     ],\n",
       "          ...,\n",
       "          [ -71.939    ,  -89.779    , -123.68     ],\n",
       "          [ -40.939003 ,  -62.779    , -103.68     ],\n",
       "          [ -40.939003 ,  -61.779    , -105.68     ]],\n",
       " \n",
       "         [[ -37.939003 ,  -40.779    ,  -29.68     ],\n",
       "          [ -36.939003 ,  -39.779    ,  -28.68     ],\n",
       "          [ -34.939003 ,  -37.779    ,  -26.68     ],\n",
       "          ...,\n",
       "          [ -27.939003 ,  -50.779    ,  -87.68     ],\n",
       "          [ -20.939003 ,  -44.779    ,  -83.68     ],\n",
       "          [  -1.939003 ,  -26.779    ,  -67.68     ]],\n",
       " \n",
       "         [[  12.060997 ,    6.2210007,   18.32     ],\n",
       "          [  14.060997 ,    8.221001 ,   20.32     ],\n",
       "          [  18.060997 ,   12.221001 ,   24.32     ],\n",
       "          ...,\n",
       "          [  32.060997 ,    3.2210007,  -32.68     ],\n",
       "          [   8.060997 ,  -22.779    ,  -60.68     ],\n",
       "          [  26.060997 ,   -3.7789993,  -43.68     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  42.060997 ,   34.221    ,   36.32     ],\n",
       "          [  41.060997 ,   33.221    ,   35.32     ],\n",
       "          [  42.060997 ,   34.221    ,   36.32     ],\n",
       "          ...,\n",
       "          [-100.939    , -108.779    , -116.68     ],\n",
       "          [-100.939    , -108.779    , -114.68     ],\n",
       "          [ -95.939    , -100.779    , -107.68     ]],\n",
       " \n",
       "         [[  40.060997 ,   32.221    ,   34.32     ],\n",
       "          [  38.060997 ,   30.221    ,   32.32     ],\n",
       "          [  40.060997 ,   32.221    ,   34.32     ],\n",
       "          ...,\n",
       "          [ -97.939    , -105.779    , -113.68     ],\n",
       "          [ -95.939    , -102.779    , -110.68     ],\n",
       "          [ -88.939    ,  -93.779    , -100.68     ]],\n",
       " \n",
       "         [[  37.060997 ,   31.221    ,   33.32     ],\n",
       "          [  35.060997 ,   29.221    ,   31.32     ],\n",
       "          [  37.060997 ,   31.221    ,   33.32     ],\n",
       "          ...,\n",
       "          [ -98.939    , -106.779    , -114.68     ],\n",
       "          [ -94.939    , -101.779    , -109.68     ],\n",
       "          [ -84.939    ,  -91.779    ,  -99.68     ]]]], dtype=float32),\n",
       " array([[[[-102.939    ,  -97.779    ,  -81.68     ],\n",
       "          [-101.939    ,  -96.779    ,  -80.68     ],\n",
       "          [ -99.939    ,  -94.779    ,  -78.68     ],\n",
       "          ...,\n",
       "          [ -65.939    ,  -65.779    ,  -58.68     ],\n",
       "          [ -64.939    ,  -64.779    ,  -57.68     ],\n",
       "          [ -65.939    ,  -65.779    ,  -58.68     ]],\n",
       " \n",
       "         [[-102.939    ,  -97.779    ,  -81.68     ],\n",
       "          [-101.939    ,  -96.779    ,  -80.68     ],\n",
       "          [-100.939    ,  -95.779    ,  -79.68     ],\n",
       "          ...,\n",
       "          [ -68.939    ,  -69.779    ,  -58.68     ],\n",
       "          [ -65.939    ,  -66.779    ,  -55.68     ],\n",
       "          [ -65.939    ,  -66.779    ,  -55.68     ]],\n",
       " \n",
       "         [[-101.939    ,  -96.779    ,  -80.68     ],\n",
       "          [-101.939    ,  -96.779    ,  -80.68     ],\n",
       "          [-100.939    ,  -95.779    ,  -79.68     ],\n",
       "          ...,\n",
       "          [ -69.939    ,  -73.779    ,  -60.68     ],\n",
       "          [ -64.939    ,  -68.779    ,  -55.68     ],\n",
       "          [ -63.939003 ,  -67.779    ,  -54.68     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  41.060997 ,   35.221    ,   55.32     ],\n",
       "          [  41.060997 ,   35.221    ,   55.32     ],\n",
       "          [  41.060997 ,   35.221    ,   55.32     ],\n",
       "          ...,\n",
       "          [  -4.939003 ,   -5.7789993,   21.32     ],\n",
       "          [ -14.939003 ,  -15.778999 ,   11.32     ],\n",
       "          [ -21.939003 ,  -22.779    ,    4.3199997]],\n",
       " \n",
       "         [[  41.060997 ,   35.221    ,   55.32     ],\n",
       "          [  41.060997 ,   35.221    ,   55.32     ],\n",
       "          [  41.060997 ,   35.221    ,   55.32     ],\n",
       "          ...,\n",
       "          [  -4.939003 ,   -5.7789993,   21.32     ],\n",
       "          [ -14.939003 ,  -15.778999 ,   11.32     ],\n",
       "          [ -22.939003 ,  -23.779    ,    3.3199997]],\n",
       " \n",
       "         [[  40.060997 ,   34.221    ,   54.32     ],\n",
       "          [  40.060997 ,   34.221    ,   54.32     ],\n",
       "          [  40.060997 ,   34.221    ,   54.32     ],\n",
       "          ...,\n",
       "          [  -4.939003 ,   -5.7789993,   21.32     ],\n",
       "          [ -14.939003 ,  -15.778999 ,   11.32     ],\n",
       "          [ -22.939003 ,  -23.779    ,    3.3199997]]]], dtype=float32),\n",
       " array([[[[ 151.061     ,  137.22101   ,  131.32      ],\n",
       "          [ 151.061     ,  138.22101   ,  131.32      ],\n",
       "          [ 151.061     ,  138.22101   ,  131.32      ],\n",
       "          ...,\n",
       "          [ 123.061     ,   72.221     ,   63.32      ],\n",
       "          [ 118.061     ,   83.221     ,   71.32      ],\n",
       "          [  56.060997  ,   35.221     ,   21.32      ]],\n",
       " \n",
       "         [[ 151.061     ,  137.22101   ,  131.32      ],\n",
       "          [ 151.061     ,  138.22101   ,  131.32      ],\n",
       "          [ 151.061     ,  138.22101   ,  131.32      ],\n",
       "          ...,\n",
       "          [ 112.061     ,   61.221     ,   52.32      ],\n",
       "          [ 102.061     ,   67.221     ,   54.32      ],\n",
       "          [  63.060997  ,   43.221     ,   27.32      ]],\n",
       " \n",
       "         [[ 151.061     ,  137.22101   ,  131.32      ],\n",
       "          [ 151.061     ,  138.22101   ,  131.32      ],\n",
       "          [ 151.061     ,  138.22101   ,  131.32      ],\n",
       "          ...,\n",
       "          [ 102.061     ,   52.221     ,   41.32      ],\n",
       "          [  85.061     ,   50.221     ,   37.32      ],\n",
       "          [  83.061     ,   63.221     ,   47.32      ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -96.939     , -114.779     , -123.68      ],\n",
       "          [ -98.939     , -116.779     , -123.68      ],\n",
       "          [ -98.939     , -116.779     , -123.68      ],\n",
       "          ...,\n",
       "          [  -7.939003  ,   -4.7789993 ,   17.32      ],\n",
       "          [  -6.939003  ,   -3.7789993 ,   18.32      ],\n",
       "          [  -4.939003  ,   -1.7789993 ,   20.32      ]],\n",
       " \n",
       "         [[ -95.939     , -113.779     , -123.68      ],\n",
       "          [ -98.939     , -116.779     , -123.68      ],\n",
       "          [ -98.939     , -116.779     , -123.68      ],\n",
       "          ...,\n",
       "          [  -3.939003  ,   -0.7789993 ,   21.32      ],\n",
       "          [  -5.939003  ,   -4.7789993 ,   17.32      ],\n",
       "          [  -7.939003  ,   -6.7789993 ,   15.32      ]],\n",
       " \n",
       "         [[ -95.939     , -113.779     , -123.68      ],\n",
       "          [ -98.939     , -116.779     , -123.68      ],\n",
       "          [ -98.939     , -116.779     , -123.68      ],\n",
       "          ...,\n",
       "          [  -0.939003  ,    0.22100067,   22.32      ],\n",
       "          [  -4.939003  ,   -3.7789993 ,   18.32      ],\n",
       "          [  -8.939003  ,   -7.7789993 ,   14.32      ]]]], dtype=float32),\n",
       " array([[[[  -7.939003 ,   -8.778999 ,   24.32     ],\n",
       "          [  -8.939003 ,   -9.778999 ,   23.32     ],\n",
       "          [ -10.939003 ,  -11.778999 ,   21.32     ],\n",
       "          ...,\n",
       "          [ -30.939003 ,  -34.779    ,   -7.6800003],\n",
       "          [ -31.939003 ,  -35.779    ,   -8.68     ],\n",
       "          [ -31.939003 ,  -35.779    ,   -8.68     ]],\n",
       " \n",
       "         [[  -6.939003 ,   -7.7789993,   25.32     ],\n",
       "          [  -7.939003 ,   -8.778999 ,   24.32     ],\n",
       "          [  -9.939003 ,  -10.778999 ,   22.32     ],\n",
       "          ...,\n",
       "          [ -30.939003 ,  -34.779    ,   -7.6800003],\n",
       "          [ -31.939003 ,  -35.779    ,   -8.68     ],\n",
       "          [ -31.939003 ,  -35.779    ,   -8.68     ]],\n",
       " \n",
       "         [[  -6.939003 ,   -7.7789993,   25.32     ],\n",
       "          [  -7.939003 ,   -8.778999 ,   24.32     ],\n",
       "          [  -9.939003 ,  -10.778999 ,   22.32     ],\n",
       "          ...,\n",
       "          [ -31.939003 ,  -35.779    ,   -8.68     ],\n",
       "          [ -32.939003 ,  -36.779    ,   -9.68     ],\n",
       "          [ -32.939003 ,  -36.779    ,   -9.68     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -81.939    ,    1.2210007,    7.3199997],\n",
       "          [ -96.939    ,   -6.7789993,   -4.6800003],\n",
       "          [ -93.939    ,    5.2210007,    4.3199997],\n",
       "          ...,\n",
       "          [ -84.939    ,  -60.779    ,  -63.68     ],\n",
       "          [ -93.939    ,  -68.779    ,  -71.68     ],\n",
       "          [-102.939    ,  -77.779    ,  -80.68     ]],\n",
       " \n",
       "         [[ -92.939    ,  -30.779    ,  -23.68     ],\n",
       "          [-103.939    ,  -31.779    ,  -28.68     ],\n",
       "          [-103.939    ,  -21.779    ,  -23.68     ],\n",
       "          ...,\n",
       "          [ -91.939    ,  -66.779    ,  -69.68     ],\n",
       "          [ -97.939    ,  -69.779    ,  -73.68     ],\n",
       "          [-103.939    ,  -75.779    ,  -79.68     ]],\n",
       " \n",
       "         [[ -94.939    ,  -44.779    ,  -37.68     ],\n",
       "          [-100.939    ,  -36.779    ,  -34.68     ],\n",
       "          [-103.939    ,  -27.779    ,  -27.68     ],\n",
       "          ...,\n",
       "          [ -87.939    ,  -62.779    ,  -65.68     ],\n",
       "          [ -84.939    ,  -56.779    ,  -60.68     ],\n",
       "          [ -85.939    ,  -55.779    ,  -59.68     ]]]], dtype=float32),\n",
       " array([[[[ -63.939003,  -81.779   ,  -33.68    ],\n",
       "          [ -72.939   ,  -88.779   ,  -46.68    ],\n",
       "          [ -82.939   ,  -96.779   ,  -64.68    ],\n",
       "          ...,\n",
       "          [-103.939   , -116.779   , -120.68    ],\n",
       "          [-103.939   , -116.779   , -120.68    ],\n",
       "          [-103.939   , -116.779   , -120.68    ]],\n",
       " \n",
       "         [[ -87.939   ,  -86.779   ,  -44.68    ],\n",
       "          [ -86.939   ,  -88.779   ,  -51.68    ],\n",
       "          [ -84.939   ,  -89.779   ,  -59.68    ],\n",
       "          ...,\n",
       "          [-103.939   , -116.779   , -120.68    ],\n",
       "          [-103.939   , -116.779   , -120.68    ],\n",
       "          [-103.939   , -116.779   , -120.68    ]],\n",
       " \n",
       "         [[-101.939   ,  -80.779   ,  -41.68    ],\n",
       "          [ -97.939   ,  -80.779   ,  -46.68    ],\n",
       "          [ -88.939   ,  -79.779   ,  -51.68    ],\n",
       "          ...,\n",
       "          [-103.939   , -116.779   , -119.68    ],\n",
       "          [-103.939   , -116.779   , -120.68    ],\n",
       "          [-103.939   , -116.779   , -120.68    ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -95.939   ,  -94.779   ,  -65.68    ],\n",
       "          [ -95.939   ,  -94.779   ,  -65.68    ],\n",
       "          [ -93.939   ,  -94.779   ,  -67.68    ],\n",
       "          ...,\n",
       "          [ -95.939   ,  -89.779   ,  -39.68    ],\n",
       "          [ -94.939   ,  -88.779   ,  -38.68    ],\n",
       "          [ -94.939   ,  -87.779   ,  -39.68    ]],\n",
       " \n",
       "         [[ -97.939   ,  -95.779   ,  -70.68    ],\n",
       "          [ -97.939   ,  -95.779   ,  -70.68    ],\n",
       "          [ -95.939   ,  -94.779   ,  -72.68    ],\n",
       "          ...,\n",
       "          [-100.939   ,  -93.779   ,  -45.68    ],\n",
       "          [-100.939   ,  -92.779   ,  -47.68    ],\n",
       "          [ -98.939   ,  -93.779   ,  -47.68    ]],\n",
       " \n",
       "         [[ -99.939   ,  -96.779   ,  -74.68    ],\n",
       "          [ -99.939   ,  -95.779   ,  -75.68    ],\n",
       "          [ -97.939   ,  -96.779   ,  -75.68    ],\n",
       "          ...,\n",
       "          [-100.939   ,  -92.779   ,  -47.68    ],\n",
       "          [-102.939   ,  -94.779   ,  -49.68    ],\n",
       "          [-100.939   ,  -94.779   ,  -50.68    ]]]], dtype=float32),\n",
       " array([[[[-63.939003 , -71.779    , -77.68     ],\n",
       "          [-67.939    , -75.779    , -81.68     ],\n",
       "          [-63.939003 , -71.779    , -77.68     ],\n",
       "          ...,\n",
       "          [-74.939    , -80.779    , -78.68     ],\n",
       "          [-86.939    , -86.779    , -85.68     ],\n",
       "          [-35.939003 , -31.779    , -29.68     ]],\n",
       " \n",
       "         [[-69.939    , -77.779    , -83.68     ],\n",
       "          [-72.939    , -80.779    , -86.68     ],\n",
       "          [-66.939    , -74.779    , -80.68     ],\n",
       "          ...,\n",
       "          [-67.939    , -73.779    , -71.68     ],\n",
       "          [-75.939    , -75.779    , -74.68     ],\n",
       "          [-58.939003 , -53.779    , -53.68     ]],\n",
       " \n",
       "         [[-75.939    , -83.779    , -89.68     ],\n",
       "          [-76.939    , -84.779    , -90.68     ],\n",
       "          [-69.939    , -77.779    , -83.68     ],\n",
       "          ...,\n",
       "          [-72.939    , -77.779    , -77.68     ],\n",
       "          [-75.939    , -75.779    , -74.68     ],\n",
       "          [-53.939003 , -50.779    , -50.68     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 62.060997 ,  60.221    ,  57.32     ],\n",
       "          [ 86.061    ,  85.221    ,  82.32     ],\n",
       "          [ 54.060997 ,  53.221    ,  52.32     ],\n",
       "          ...,\n",
       "          [ 18.060997 ,  17.221    ,  16.32     ],\n",
       "          [ 22.060997 ,  16.221    ,  18.32     ],\n",
       "          [-15.939003 , -26.779    , -23.68     ]],\n",
       " \n",
       "         [[ 53.060997 ,  51.221    ,  48.32     ],\n",
       "          [ 83.061    ,  82.221    ,  79.32     ],\n",
       "          [ 56.060997 ,  55.221    ,  54.32     ],\n",
       "          ...,\n",
       "          [-21.939003 , -20.779    , -21.68     ],\n",
       "          [-11.939003 , -16.779    , -16.68     ],\n",
       "          [  2.060997 ,  -5.7789993,  -3.6800003]],\n",
       " \n",
       "         [[ 59.060997 ,  57.221    ,  54.32     ],\n",
       "          [ 76.061    ,  75.221    ,  72.32     ],\n",
       "          [ 45.060997 ,  44.221    ,  43.32     ],\n",
       "          ...,\n",
       "          [-25.939003 , -24.779    , -25.68     ],\n",
       "          [ -5.939003 , -10.778999 , -10.68     ],\n",
       "          [ 50.060997 ,  43.221    ,  43.32     ]]]], dtype=float32),\n",
       " array([[[[ 4.3060997e+01, -1.7789993e+00, -5.7680000e+01],\n",
       "          [ 5.3060997e+01,  7.2210007e+00, -4.4680000e+01],\n",
       "          [ 4.8060997e+01,  2.2100067e-01, -4.6680000e+01],\n",
       "          ...,\n",
       "          [ 8.1060997e+01,  8.5221001e+01,  7.5320000e+01],\n",
       "          [ 6.7060997e+01,  7.1221001e+01,  6.1320000e+01],\n",
       "          [ 6.9060997e+01,  7.3221001e+01,  6.3320000e+01]],\n",
       " \n",
       "         [[ 4.6060997e+01,  4.2210007e+00, -4.7680000e+01],\n",
       "          [ 4.9060997e+01,  6.2210007e+00, -4.1680000e+01],\n",
       "          [ 4.0060997e+01, -4.7789993e+00, -4.7680000e+01],\n",
       "          ...,\n",
       "          [ 7.8060997e+01,  8.2221001e+01,  7.2320000e+01],\n",
       "          [ 6.8060997e+01,  7.2221001e+01,  6.2320000e+01],\n",
       "          [ 7.2060997e+01,  7.6221001e+01,  6.6320000e+01]],\n",
       " \n",
       "         [[ 3.5060997e+01, -7.7899933e-01, -4.5680000e+01],\n",
       "          [ 3.5060997e+01, -1.7789993e+00, -4.4680000e+01],\n",
       "          [ 2.8060997e+01, -1.0778999e+01, -4.7680000e+01],\n",
       "          ...,\n",
       "          [ 8.5060997e+01,  8.9221001e+01,  7.9320000e+01],\n",
       "          [ 7.2060997e+01,  7.6221001e+01,  6.6320000e+01],\n",
       "          [ 7.6060997e+01,  8.0221001e+01,  7.0320000e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-8.4939003e+01, -9.8778999e+01, -1.0368000e+02],\n",
       "          [-9.1939003e+01, -1.0577900e+02, -1.1068000e+02],\n",
       "          [-8.2939003e+01, -9.5778999e+01, -1.0268000e+02],\n",
       "          ...,\n",
       "          [-9.0939003e+01, -1.0077900e+02, -1.0968000e+02],\n",
       "          [-5.7939003e+01, -6.8778999e+01, -7.5680000e+01],\n",
       "          [-1.5939003e+01, -2.6778999e+01, -3.3680000e+01]],\n",
       " \n",
       "         [[-9.3939003e+01, -1.0777900e+02, -1.1268000e+02],\n",
       "          [-1.0093900e+02, -1.1477900e+02, -1.1968000e+02],\n",
       "          [-8.9939003e+01, -1.0377900e+02, -1.0868000e+02],\n",
       "          ...,\n",
       "          [-2.9939003e+01, -3.9778999e+01, -4.8680000e+01],\n",
       "          [-1.2939003e+01, -2.3778999e+01, -3.0680000e+01],\n",
       "          [ 8.0609970e+00, -2.7789993e+00, -9.6800003e+00]],\n",
       " \n",
       "         [[-8.8939003e+01, -1.0277900e+02, -1.0768000e+02],\n",
       "          [-9.8939003e+01, -1.1277900e+02, -1.1768000e+02],\n",
       "          [-9.0939003e+01, -1.0477900e+02, -1.0968000e+02],\n",
       "          ...,\n",
       "          [-1.9390030e+00, -1.1778999e+01, -2.0680000e+01],\n",
       "          [-2.9390030e+00, -1.3778999e+01, -2.0680000e+01],\n",
       "          [ 6.0997009e-02, -1.0778999e+01, -1.7680000e+01]]]],\n",
       "       dtype=float32),\n",
       " array([[[[ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          [ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          [ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          ...,\n",
       "          [ -90.939   ,  -95.779   , -112.68    ],\n",
       "          [ -95.939   , -100.779   , -117.68    ],\n",
       "          [ -85.939   ,  -90.779   , -107.68    ]],\n",
       " \n",
       "         [[ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          [ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          [ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          ...,\n",
       "          [ -73.939   ,  -78.779   ,  -95.68    ],\n",
       "          [ -79.939   ,  -84.779   , -101.68    ],\n",
       "          [ -73.939   ,  -78.779   ,  -95.68    ]],\n",
       " \n",
       "         [[ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          [ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          [ 151.061   ,  138.22101 ,  130.32    ],\n",
       "          ...,\n",
       "          [ -52.939003,  -57.779   ,  -74.68    ],\n",
       "          [ -60.939003,  -65.779   ,  -82.68    ],\n",
       "          [ -57.939003,  -62.779   ,  -79.68    ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -57.939003,  -67.779   ,  -66.68    ],\n",
       "          [ -56.939003,  -66.779   ,  -68.68    ],\n",
       "          [ -47.939003,  -61.779   ,  -66.68    ],\n",
       "          ...,\n",
       "          [ -17.939003,  -33.779   ,  -44.68    ],\n",
       "          [ -19.939003,  -35.779   ,  -46.68    ],\n",
       "          [ -16.939003,  -32.779   ,  -43.68    ]],\n",
       " \n",
       "         [[ -55.939003,  -65.779   ,  -64.68    ],\n",
       "          [ -57.939003,  -67.779   ,  -69.68    ],\n",
       "          [ -49.939003,  -63.779   ,  -68.68    ],\n",
       "          ...,\n",
       "          [ -17.939003,  -33.779   ,  -44.68    ],\n",
       "          [ -21.939003,  -37.779   ,  -48.68    ],\n",
       "          [ -17.939003,  -33.779   ,  -44.68    ]],\n",
       " \n",
       "         [[ -54.939003,  -64.779   ,  -63.68    ],\n",
       "          [ -57.939003,  -67.779   ,  -69.68    ],\n",
       "          [ -48.939003,  -62.779   ,  -67.68    ],\n",
       "          ...,\n",
       "          [ -13.939003,  -29.779   ,  -40.68    ],\n",
       "          [ -18.939003,  -34.779   ,  -45.68    ],\n",
       "          [ -14.939003,  -30.779   ,  -41.68    ]]]], dtype=float32),\n",
       " array([[[[  42.060997 ,  -26.779    ,  -92.68     ],\n",
       "          [  46.060997 ,  -24.779    ,  -90.68     ],\n",
       "          [  49.060997 ,  -21.779    ,  -87.68     ],\n",
       "          ...,\n",
       "          [ 101.061    ,   10.221001 ,  -62.68     ],\n",
       "          [  97.061    ,    6.2210007,  -66.68     ],\n",
       "          [  94.061    ,    3.2210007,  -69.68     ]],\n",
       " \n",
       "         [[  46.060997 ,  -24.779    ,  -90.68     ],\n",
       "          [  48.060997 ,  -22.779    ,  -88.68     ],\n",
       "          [  51.060997 ,  -19.779    ,  -85.68     ],\n",
       "          ...,\n",
       "          [ 102.061    ,   11.221001 ,  -61.68     ],\n",
       "          [  98.061    ,    7.2210007,  -65.68     ],\n",
       "          [  95.061    ,    4.2210007,  -68.68     ]],\n",
       " \n",
       "         [[  47.060997 ,  -23.779    ,  -89.68     ],\n",
       "          [  49.060997 ,  -21.779    ,  -87.68     ],\n",
       "          [  54.060997 ,  -18.779    ,  -84.68     ],\n",
       "          ...,\n",
       "          [ 103.061    ,   12.221001 ,  -60.68     ],\n",
       "          [  99.061    ,    8.221001 ,  -64.68     ],\n",
       "          [  96.061    ,    5.2210007,  -67.68     ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -65.939    ,  -98.779    , -122.68     ],\n",
       "          [ -62.939003 ,  -96.779    , -118.68     ],\n",
       "          [ -61.939003 ,  -93.779    , -115.68     ],\n",
       "          ...,\n",
       "          [ -60.939003 , -103.779    , -121.68     ],\n",
       "          [ -54.939003 ,  -98.779    , -114.68     ],\n",
       "          [ -53.939003 ,  -97.779    , -113.68     ]],\n",
       " \n",
       "         [[ -18.939003 ,  -55.779    ,  -80.68     ],\n",
       "          [ -14.939003 ,  -49.779    ,  -74.68     ],\n",
       "          [  -9.939003 ,  -42.779    ,  -66.68     ],\n",
       "          ...,\n",
       "          [ -61.939003 , -104.779    , -122.68     ],\n",
       "          [ -54.939003 ,  -98.779    , -114.68     ],\n",
       "          [ -45.939003 ,  -91.779    , -107.68     ]],\n",
       " \n",
       "         [[  11.060997 ,  -25.779    ,  -52.68     ],\n",
       "          [  16.060997 ,  -20.779    ,  -47.68     ],\n",
       "          [  17.060997 ,  -17.779    ,  -42.68     ],\n",
       "          ...,\n",
       "          [ -60.939003 , -103.779    , -121.68     ],\n",
       "          [ -53.939003 ,  -99.779    , -115.68     ],\n",
       "          [ -43.939003 ,  -89.779    , -105.68     ]]]], dtype=float32)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape = image_size, name = 'input_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-96571f16397f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "myf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/alumno04/dev_samir/image_processing_project'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = K.variable(np.arange (27))\n",
    "#a = np.split(y_pred,[6])\n",
    "#b = a[0]\n",
    "#c = a[1]\n",
    "x = K.slice(y_pred, [1],[6])\n",
    "y = K.slice(y_pred, [6],[-1])\n",
    "z = K.reshape(y_pred,[3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = K.slice(z, [2,0,0],[1,-1,-1])\n",
    "v = K.mean(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[18., 19., 20.],\n",
       "        [21., 22., 23.],\n",
       "        [24., 25., 26.]]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loss_f(y_true, y_pred):\n",
    "    x = K.slice(y_pred, [6],[-1])\n",
    "        \n",
    "    parameters = K.slice(y_pred,[0],[-1])\n",
    "    \n",
    "    image_pred = K.reshape(x,[224,224,3])\n",
    "    \n",
    "    image_true = K.slice(y_true,[6],[-1])\n",
    "    \n",
    "    # Contrast\n",
    "    contrast_mean = K.mean(image_pred)\n",
    "    contrast_degenerate = K.zeros(224,224,3) + contrast_mean\n",
    "    \n",
    "    image_pred = parameters[0] * image_pred + (1-parameters[0])*contrast_degenerate\n",
    "    image_pred = K.clip(image_pred,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 6), dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = K.variable(np.arange(150534))\n",
    "y_true = K.variable(np.arange(150534))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loss_f(y_true, y_pred):\n",
    "    \n",
    "        \n",
    "    parameter_1 = K.slice(y_pred,[0],[1])\n",
    "    parameter_2 = K.slice(y_pred,[1],[1])\n",
    "    parameter_3 = K.slice(y_pred,[2],[1])\n",
    "    parameter_4 = K.slice(y_pred,[3],[1])\n",
    "    parameter_5 = K.slice(y_pred,[4],[1])\n",
    "    parameter_6 = K.slice(y_pred,[5],[1])\n",
    "    \n",
    "    x = K.slice(y_pred, [6],[-1])\n",
    "    \n",
    "    image_pred = K.reshape(x,[224,224,3])\n",
    "    \n",
    "    x = K.slice(y_true,[6],[-1])\n",
    "    \n",
    "    image_true = K.reshape(x,[224,224,3])\n",
    "    \n",
    "    # Contrast\n",
    "    contrast_mean = K.mean(image_pred)\n",
    "    contrast_degenerate = K.zeros([224,224,3]) + contrast_mean\n",
    "    \n",
    "    image_pred = parameter_1 * image_pred + (1-parameter_1)*contrast_degenerate\n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "     # Brightness\n",
    "    #brightness_degenerate = np.zeros(image_pred.shape)\n",
    "    \n",
    "    image_pred = parameter_2 * image_pred # + (1 - parameters[1]) * brightness_degenerate\n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "    # Color Saturation\n",
    "    \n",
    "    saturation_degenerate = K.mean(image_pred,2)\n",
    "    \n",
    "    red_layer = K.slice(image_pred,[0,0,0],[-1,-1,1])\n",
    "    blue_layer = K.slice(image_pred,[0,0,1],[-1,-1,1])\n",
    "    green_layer = K.slice(image_pred,[0,0,2],[-1,-1,1])\n",
    "    \n",
    "    red_layer_ = (parameter_3 * red_layer) + K.expand_dims( (1- parameter_3) * saturation_degenerate, axis= 2)\n",
    "    blue_layer_ = (parameter_3 * blue_layer) +  K.expand_dims( (1- parameter_3) * saturation_degenerate, axis= 2)\n",
    "    green_layer_ = (parameter_3 * green_layer) +  K.expand_dims( (1- parameter_3) * saturation_degenerate, axis= 2)\n",
    "    \n",
    "    image_pred = K.concatenate ([red_layer_, blue_layer_, green_layer_], axis =2)\n",
    "    \n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "    # White Balance\n",
    "    red_layer = K.slice(image_pred,[0,0,0],[-1,-1,1])\n",
    "    blue_layer = K.slice(image_pred,[0,0,1],[-1,-1,1])\n",
    "    green_layer = K.slice(image_pred,[0,0,2],[-1,-1,1]) \n",
    "    \n",
    "    red_layer_ = (parameter_4 * red_layer) \n",
    "    blue_layer_ = (parameter_5 * blue_layer)\n",
    "    green_layer_ = (parameter_6 * green_layer)\n",
    "    \n",
    "    image_pred = K.concatenate ([red_layer_, blue_layer_, green_layer_], axis =2)\n",
    "    \n",
    "    image_pred = K.clip(image_pred,0,1)\n",
    "    \n",
    "    mse = K.mean(K.square(image_pred - image_true))\n",
    "    \n",
    "    return  mse \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7553571000.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(_loss_f(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
